{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 15,460 rows\n",
      "âœ… ìœ íš¨í•œ stock_code + rcept_dt ì¡°í•© ìˆ˜: 15,460\n",
      "  stock_code   rcept_dt\n",
      "0     900290 2025-06-20\n",
      "1     900290 2025-03-19\n",
      "2     900290 2024-12-10\n",
      "3     900290 2024-11-20\n",
      "4     900290 2024-11-06\n",
      "ğŸ“ ì €ì¥ ì™„ë£Œ: /Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/base_for_price_check.csv\n"
     ]
    }
   ],
   "source": [
    "# ê²€ì¦ ì „ìš© (1ë‹¨ê³„): ë°°ë‹¹ ê³µì‹œ ë°ì´í„°ì—ì„œ stock_code, ê³µì‹œì¼ ì¶”ì¶œ\n",
    "import pandas as pd\n",
    "\n",
    "# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "path = \"/Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/dividend_ml_ready.csv\"\n",
    "df_div = pd.read_csv(path, dtype={\"stock_code\": str, \"rcept_no\": str})\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_div):,} rows\")\n",
    "\n",
    "# 2ï¸âƒ£ ê³µì‹œì¼(rcept_dt) ì¶”ì¶œ â†’ rcept_no ì• 8ìë¦¬\n",
    "df_div[\"rcept_dt\"] = pd.to_datetime(df_div[\"rcept_no\"].str[:8], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "# 3ï¸âƒ£ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì •ì œ\n",
    "df_base = df_div[[\"stock_code\", \"rcept_dt\"]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 4ï¸âƒ£ í™•ì¸\n",
    "print(f\"âœ… ìœ íš¨í•œ stock_code + rcept_dt ì¡°í•© ìˆ˜: {len(df_base):,}\")\n",
    "print(df_base.head())\n",
    "\n",
    "# 5ï¸âƒ£ ì €ì¥ (price_fetcher ì´í›„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)\n",
    "save_path = \"/Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/base_for_price_check.csv\"\n",
    "df_base.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"ğŸ“ ì €ì¥ ì™„ë£Œ: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¤€ ë°ì´í„° ë¡œë“œ: 15,460 rows\n",
      "ğŸ“¦ ì£¼ê°€ ìˆ˜ì§‘ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1682/1682 [05:56<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì£¼ê°€ ìˆ˜ì§‘ ì™„ë£Œ: 752,906 rows\n",
      "ğŸ”— ë³‘í•© í›„ ë°ì´í„° ìˆ˜: 7,638,780\n",
      "ğŸ” ê·¸ë£¹ ìˆ˜: 4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating windows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4022/4022 [00:00<00:00, 5901.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²€ì¦ ê²°ê³¼ ìƒì„±: (4022, 3)\n",
      "\n",
      "Â±10ê±°ë˜ì¼ ìœˆë„ìš° í™•ë³´ ë¶„í¬ (n_days):\n",
      "n_days\n",
      "11      92\n",
      "12       1\n",
      "13       1\n",
      "16       1\n",
      "19       1\n",
      "20       4\n",
      "21    3922\n",
      "\n",
      "â–¶ ìœˆë„ìš° ë¶€ì¡± ì´ë²¤íŠ¸ ìˆ˜: 100\n",
      "\n",
      "-- ë¶€ì¡± ì˜ˆì‹œ (ìµœì´ˆ 5ê±´) --\n",
      "stock_code   rcept_dt  n_days\n",
      "    100120 2013-02-08      11\n",
      "    100130 2013-03-04      11\n",
      "    100220 2013-02-27      11\n",
      "    100250 2013-02-07      11\n",
      "    100660 2013-02-28      11\n",
      "ğŸ“ ê²€ì¦ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: /Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/window_check_result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ê²€ì¦ íŒŒì´í”„ë¼ì¸\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import timedelta\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "# 1ï¸âƒ£ ê¸°ì¤€ í…Œì´ë¸” ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = \"/Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/base_for_price_check.csv\"\n",
    "df_base = pd.read_csv(base_path, dtype={\"stock_code\": str})\n",
    "df_base[\"rcept_dt\"] = pd.to_datetime(df_base[\"rcept_dt\"])\n",
    "print(f\"âœ… ê¸°ì¤€ ë°ì´í„° ë¡œë“œ: {len(df_base):,} rows\")\n",
    "\n",
    "# 2ï¸âƒ£ ì£¼ê°€ ìˆ˜ì§‘ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fetch_price_history(code: str, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"FDRì—ì„œ í•´ë‹¹ ì¢…ëª©ì½”ë“œì˜ ì£¼ê°€ ìˆ˜ì§‘\"\"\"\n",
    "    try:\n",
    "        df = fdr.DataReader(code, start, end)\n",
    "        df = df.reset_index()[[\"Date\", \"Close\", \"Volume\"]]\n",
    "        df[\"stock_code\"] = code\n",
    "        df = df.rename(columns={\"Date\": \"date\", \"Close\": \"close\", \"Volume\": \"volume\"})\n",
    "        return df\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 3ï¸âƒ£ ì¢…ëª©ë³„ ì£¼ê°€ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "codes = df_base[\"stock_code\"].unique()\n",
    "price_all = []\n",
    "\n",
    "print(\"ğŸ“¦ ì£¼ê°€ ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "for code in tqdm(codes):\n",
    "    start_date = (df_base[df_base[\"stock_code\"] == code][\"rcept_dt\"].min() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "    end_date   = (df_base[df_base[\"stock_code\"] == code][\"rcept_dt\"].max() + timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "    df_price = fetch_price_history(code, start_date, end_date)\n",
    "    price_all.append(df_price)\n",
    "\n",
    "df_price_all = pd.concat(price_all, ignore_index=True)\n",
    "df_price_all[\"date\"] = pd.to_datetime(df_price_all[\"date\"])\n",
    "print(f\"âœ… ì£¼ê°€ ìˆ˜ì§‘ ì™„ë£Œ: {len(df_price_all):,} rows\")\n",
    "\n",
    "# 4ï¸âƒ£ ë³‘í•©ì„ ìœ„í•œ ì»¬ëŸ¼ ì •ì œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_merge = df_base.merge(df_price_all, on=\"stock_code\", how=\"left\")\n",
    "df_merge = df_merge[df_merge[\"date\"].notna()]\n",
    "print(f\"ğŸ”— ë³‘í•© í›„ ë°ì´í„° ìˆ˜: {len(df_merge):,}\")\n",
    "\n",
    "# 5ï¸âƒ£ ìœˆë„ìš° ì¶”ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def select_trading_window(df_group: pd.DataFrame,\n",
    "                          dt: pd.Timestamp,\n",
    "                          window: int = 10) -> pd.DataFrame:\n",
    "    dfg = df_group.sort_values(\"date\").reset_index(drop=True)\n",
    "    pos = dfg[\"date\"].searchsorted(dt)\n",
    "    start = max(pos - window, 0)\n",
    "    end   = min(pos + window + 1, len(dfg))\n",
    "    return dfg.iloc[start:end]\n",
    "\n",
    "# 6ï¸âƒ£ ì¢…ëª©ë³„ ê³µì‹œì¼ Â±10ê±°ë˜ì¼ ìœˆë„ìš° í™•ë³´ ì—¬ë¶€ ê²€ì¦ â”€â”€â”€â”€â”€\n",
    "records = []\n",
    "grouped = df_merge.groupby([\"stock_code\", \"rcept_dt\"])\n",
    "print(\"ğŸ” ê·¸ë£¹ ìˆ˜:\", grouped.ngroups)\n",
    "\n",
    "for (code, dt), grp in tqdm(grouped, total=grouped.ngroups, desc=\"Validating windows\"):\n",
    "    if grp.empty:\n",
    "        n = 0\n",
    "    else:\n",
    "        win = select_trading_window(grp, dt, window=10)\n",
    "        n = len(win)\n",
    "    records.append({\n",
    "        \"stock_code\": code,\n",
    "        \"rcept_dt\":   dt,\n",
    "        \"n_days\":     n\n",
    "    })\n",
    "\n",
    "df_check = pd.DataFrame(records)\n",
    "print(\"âœ… ê²€ì¦ ê²°ê³¼ ìƒì„±:\", df_check.shape)\n",
    "\n",
    "# 7ï¸âƒ£ ê²°ê³¼ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dist = df_check[\"n_days\"].value_counts().sort_index()\n",
    "print(\"\\nÂ±10ê±°ë˜ì¼ ìœˆë„ìš° í™•ë³´ ë¶„í¬ (n_days):\")\n",
    "print(dist.to_string())\n",
    "\n",
    "# 8ï¸âƒ£ ë¶€ì¡± ì´ë²¤íŠ¸ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "missing = df_check[df_check[\"n_days\"] < 21]\n",
    "print(f\"\\nâ–¶ ìœˆë„ìš° ë¶€ì¡± ì´ë²¤íŠ¸ ìˆ˜: {len(missing):,}\")\n",
    "if not missing.empty:\n",
    "    print(\"\\n-- ë¶€ì¡± ì˜ˆì‹œ (ìµœì´ˆ 5ê±´) --\")\n",
    "    print(missing.head().to_string(index=False))\n",
    "\n",
    "# 9ï¸âƒ£ ì„ íƒ ì €ì¥ (í•„ìš” ì‹œ)\n",
    "save_path = \"/Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/window_check_result.csv\"\n",
    "df_check.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"ğŸ“ ê²€ì¦ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ë²¤íŠ¸: 15,460ê±´  |  ì¢…ëª© ìˆ˜: 1,682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetching codes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1682/1682 [00:30<00:00, 54.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê°€ê²© ë°ì´í„° fetch ì™„ë£Œ: rows=3,296,298, ì‹¤íŒ¨ ì¢…ëª©=0\n",
      "âœ… full_price_history.csv ì €ì¥ â†’ /Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data/full_price_history.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "slicing windows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15460/15460 [00:01<00:00, 10309.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ price_history.csv ì €ì¥ (1,820,860 rows)\n",
      "\n",
      "ğŸ‰ ì „ì²´ íˆìŠ¤í† ë¦¬ ìºì‹œ & ìŠ¬ë¼ì´ìŠ¤ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 02_price_fetching.ipynb â€” ì „ì²´ íˆìŠ¤í† ë¦¬ í•œ ë²ˆë§Œ fetch & ì´ë²¤íŠ¸ë³„ ìŠ¬ë¼ì´ìŠ¤\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "import os, time, warnings, threading\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# â”€â”€ 1. ì„¤ì •\n",
    "BASE       = \"/Users/gun/Desktop/ë¯¸ë˜ì—ì…‹ AI ê³µëª¨ì „/data\"\n",
    "DIV_PATH   = os.path.join(BASE, \"dividend_ml_ready.csv\")\n",
    "HIST_PATH  = os.path.join(BASE, \"price_history.csv\")\n",
    "FAIL_PATH  = os.path.join(BASE, \"failed_codes.csv\")\n",
    "CACHE_DIR  = Path(BASE) / \"price_cache\"\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "WINDOW_DAYS = 90    # Â±ì¼ìˆ˜ (ì£¼ë§ í¬í•¨)\n",
    "MAX_RETRY   = 3\n",
    "BACKOFF     = 2.5\n",
    "N_THREADS   = 8\n",
    "\n",
    "# â”€â”€ 2. ì´ë²¤íŠ¸ ë¡œë“œ & ìƒì¥ ì¢…ëª© í•„í„°\n",
    "df_div = pd.read_csv(DIV_PATH, dtype={\"stock_code\":str,\"rcept_no\":str})\n",
    "df_div[\"stock_code\"] = df_div.stock_code.str.zfill(6)\n",
    "df_div[\"rcept_dt\"]   = pd.to_datetime(df_div.rcept_no.str[:8],\n",
    "                                      format=\"%Y%m%d\", errors=\"coerce\")\n",
    "df_base = (\n",
    "    df_div[[\"stock_code\",\"rcept_dt\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "try:\n",
    "    live = set(fdr.StockListing(\"KRX\")[\"Code\"])\n",
    "except:\n",
    "    live = set(df_base.stock_code.unique())\n",
    "df_base = df_base[df_base.stock_code.isin(live)].reset_index(drop=True)\n",
    "print(f\"âœ… ì´ë²¤íŠ¸: {len(df_base):,}ê±´  |  ì¢…ëª© ìˆ˜: {df_base.stock_code.nunique():,}\")\n",
    "\n",
    "# â”€â”€ 3. ì¢…ëª©ë³„ ì „ì²´ ê¸°ê°„ fetch í•¨ìˆ˜\n",
    "lock, failed = threading.Lock(), []\n",
    "\n",
    "def fetch_code(code: str, start: str, end: str) -> pd.DataFrame | None:\n",
    "    cache_file = CACHE_DIR / f\"{code}.csv\"\n",
    "    # â‘  ìºì‹œ ë°©ì–´: date ì¹¼ëŸ¼ì´ datetime ìœ¼ë¡œ ì˜ íŒŒì‹±ë˜ëŠ”ì§€ í™•ì¸\n",
    "    if cache_file.exists():\n",
    "        try:\n",
    "            tmp = pd.read_csv(cache_file, parse_dates=[\"date\"])\n",
    "            if (tmp[\"date\"].dtype.kind == \"M\"  # datetime64ì¸ì§€\n",
    "                and tmp[\"date\"].min() <= pd.to_datetime(start)\n",
    "                and tmp[\"date\"].max() >= pd.to_datetime(end)):\n",
    "                return tmp\n",
    "        except Exception:\n",
    "            pass  # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ìˆ˜ì§‘\n",
    "\n",
    "    # â‘¡ ì‹ ê·œ fetch ì‹œë„ (KRX â†’ plain code)\n",
    "    delay = 1.0\n",
    "    for attempt in range(1, MAX_RETRY+1):\n",
    "        try:\n",
    "            df = fdr.DataReader(f\"KRX:{code}\", start, end)\n",
    "        except:\n",
    "            try:\n",
    "                df = fdr.DataReader(code, start, end)\n",
    "            except Exception as e:\n",
    "                if attempt == MAX_RETRY:\n",
    "                    with lock:\n",
    "                        failed.append(code)\n",
    "                    return None\n",
    "                time.sleep(delay)\n",
    "                delay *= BACKOFF\n",
    "                continue\n",
    "        df = (\n",
    "            df.reset_index()[[\"Date\",\"Close\",\"Volume\"]]\n",
    "              .rename(columns={\"Date\":\"date\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "        )\n",
    "        df[\"stock_code\"] = code\n",
    "        df.to_csv(cache_file, index=False)\n",
    "        return df\n",
    "\n",
    "    return None\n",
    "\n",
    "# â”€â”€ 4. ì¢…ëª©ë³„ ìµœì†Œ/ìµœëŒ€ ì´ë²¤íŠ¸ ì¼ìì— ë§ì¶° í•œ ë²ˆë§Œ fetch\n",
    "ranges = (\n",
    "    df_base\n",
    "    .groupby(\"stock_code\")[\"rcept_dt\"]\n",
    "    .agg([\"min\",\"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "ranges[\"start\"] = (ranges[\"min\"] - timedelta(days=WINDOW_DAYS)).dt.strftime(\"%Y-%m-%d\")\n",
    "ranges[\"end\"]   = (ranges[\"max\"] + timedelta(days=WINDOW_DAYS)).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "price_dfs = []\n",
    "with ThreadPoolExecutor(max_workers=N_THREADS) as exe:\n",
    "    futures = {\n",
    "        exe.submit(fetch_code, row.stock_code, row.start, row.end): row.stock_code\n",
    "        for _, row in ranges.iterrows()\n",
    "    }\n",
    "    for fut in tqdm(futures, total=len(futures), desc=\"fetching codes\"):\n",
    "        df_code = fut.result()\n",
    "        if df_code is not None:\n",
    "            price_dfs.append(df_code)\n",
    "\n",
    "total_rows = sum(len(df) for df in price_dfs)\n",
    "print(f\"âœ… ê°€ê²© ë°ì´í„° fetch ì™„ë£Œ: rows={total_rows:,}, ì‹¤íŒ¨ ì¢…ëª©={len(failed):,}\")\n",
    "pd.DataFrame({\"failed_code\": failed}).to_csv(FAIL_PATH, index=False)\n",
    "\n",
    "# â”€â”€ 5. full_price_history.csv ì €ì¥\n",
    "df_full = pd.concat(price_dfs, ignore_index=True)\n",
    "FULL_PATH = os.path.join(BASE, \"full_price_history.csv\")\n",
    "df_full.to_csv(FULL_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… full_price_history.csv ì €ì¥ â†’ {FULL_PATH}\")\n",
    "\n",
    "# â”€â”€ 6. ì´ë²¤íŠ¸ë³„ Â±WINDOW_DAYS ìŠ¬ë¼ì´ìŠ¤\n",
    "price_map = {\n",
    "    code: grp.sort_values(\"date\").reset_index(drop=True)\n",
    "    for code, grp in df_full.groupby(\"stock_code\")\n",
    "}\n",
    "\n",
    "hist_rows = []\n",
    "for (code, dt), _ in tqdm(df_base.groupby([\"stock_code\",\"rcept_dt\"]),\n",
    "                          total=len(df_base), desc=\"slicing windows\"):\n",
    "    sub = price_map.get(code)\n",
    "    if sub is None:\n",
    "        continue\n",
    "\n",
    "    pos = sub[\"date\"].searchsorted(dt)\n",
    "    if pos >= len(sub) or sub.loc[pos,\"date\"] < dt:\n",
    "        fut = sub[\"date\"][sub[\"date\"] >= dt]\n",
    "        if fut.empty:\n",
    "            continue\n",
    "        pos = sub[\"date\"].searchsorted(fut.min())\n",
    "\n",
    "    lo = max(pos - WINDOW_DAYS, 0)\n",
    "    hi = min(pos + WINDOW_DAYS + 1, len(sub))\n",
    "    window_df = sub.iloc[lo:hi].copy()\n",
    "\n",
    "    # ì¶©ë¶„í•œ ê¸¸ì´(2*WINDOW_DAYS+1)ì¸ì§€ ì²´í¬\n",
    "    if len(window_df) < 2*WINDOW_DAYS + 1:\n",
    "        continue\n",
    "\n",
    "    window_df[\"rcept_dt\"] = dt\n",
    "    hist_rows.append(window_df)\n",
    "\n",
    "# â”€â”€ 7. price_history.csv ì €ì¥\n",
    "if hist_rows:\n",
    "    df_hist = pd.concat(hist_rows, ignore_index=True)\n",
    "    df_hist = df_hist[[\"stock_code\",\"rcept_dt\",\"date\",\"close\",\"volume\"]]\n",
    "    df_hist.to_csv(HIST_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“ price_history.csv ì €ì¥ ({len(df_hist):,} rows)\")\n",
    "else:\n",
    "    print(\"âš ï¸ ìŠ¬ë¼ì´ìŠ¤ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nğŸ‰ ì „ì²´ íˆìŠ¤í† ë¦¬ ìºì‹œ & ìŠ¬ë¼ì´ìŠ¤ ì™„ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
