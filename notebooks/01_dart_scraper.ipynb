{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_dart_scraper.ipynb\n",
    "\n",
    "이 노트북에서는  \n",
    "1. DART `corpCode.xml`을 내려받아 상장사 목록을 로드하고  \n",
    "2. 각 사별로 list.json 페이징을 돌며 공시 메타정보를 수집한 뒤  \n",
    "3. Selenium을 이용해 iframe HTML을 병렬로 가져와  \n",
    "4. 최종 결과를 `dividend_with_text.csv` / `dividend_with_text.jsonl`으로 저장합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import requests, chardet, xmltodict, json, pandas as pd\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.exceptions import ReadTimeout\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env에서 DART_API_KEY 로드\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"DART_API_KEY\")\n",
    "assert API_KEY, \"❌ .env에 DART_API_KEY를 설정하세요\"\n",
    "\n",
    "# 저장 디렉토리\n",
    "DATA_DIR = \"data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# User-Agent\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429,500,502,503,504],\n",
    "    allowed_methods=[\"GET\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "def _download_corp_code():\n",
    "    zip_path = os.path.join(DATA_DIR, \"corp_code.zip\")\n",
    "    xml_path = os.path.join(DATA_DIR, \"corp_code.xml\")\n",
    "    # 기존 캐시 삭제\n",
    "    for p in (zip_path, xml_path):\n",
    "        if os.path.exists(p): os.remove(p)\n",
    "\n",
    "    url = f\"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={API_KEY}\"\n",
    "    r = session.get(url, headers=HEADERS, timeout=30); r.raise_for_status()\n",
    "    content = r.content\n",
    "\n",
    "    # XML directly?\n",
    "    if content.lstrip().startswith(b\"<?xml\"):\n",
    "        with open(xml_path, \"wb\") as f: f.write(content)\n",
    "    else:\n",
    "        with open(zip_path, \"wb\") as f: f.write(content)\n",
    "        with zipfile.ZipFile(zip_path) as zf:\n",
    "            zf.extractall(DATA_DIR)\n",
    "        os.replace(os.path.join(DATA_DIR, \"CORPCODE.xml\"), xml_path)\n",
    "\n",
    "def load_corps() -> pd.DataFrame:\n",
    "    _download_corp_code()\n",
    "    raw = open(os.path.join(DATA_DIR, \"corp_code.xml\"), \"rb\").read()\n",
    "    enc = chardet.detect(raw)[\"encoding\"]\n",
    "    doc = xmltodict.parse(raw.decode(enc, errors=\"ignore\"))\n",
    "\n",
    "    # API 형태에 맞춰 list 뽑기\n",
    "    if \"result\" in doc:\n",
    "        lst = doc[\"result\"].get(\"list\", [])\n",
    "    else:\n",
    "        lst = doc[\"CORPCODE\"][\"list\"][\"item\"]\n",
    "    if isinstance(lst, dict): lst = [lst]\n",
    "\n",
    "    df = pd.DataFrame(lst)[[\"corp_code\",\"corp_name\",\"stock_code\"]]\n",
    "    return df[df.stock_code.str.isdigit() & df.stock_code.str.len().eq(6)].reset_index(drop=True)\n",
    "\n",
    "def list_filings(corp_code: str, bgn=\"20130101\", end=\"20250630\") -> list:\n",
    "        all_list, fail = [], 0\n",
    "        for page in range(1, 51):\n",
    "            url = (\n",
    "                f\"https://opendart.fss.or.kr/api/list.json?\"\n",
    "                f\"crtfc_key={API_KEY}&corp_code={corp_code}\"\n",
    "                f\"&bgn_de={bgn}&end_de={end}\"\n",
    "                f\"&page_count=100&page_no={page}\"\n",
    "            )\n",
    "            try:\n",
    "                r = session.get(url, headers=HEADERS, timeout=20)\n",
    "                r.raise_for_status()\n",
    "                page_list = r.json().get(\"list\", [])\n",
    "            except ReadTimeout:\n",
    "                fail += 1\n",
    "                time.sleep(1)\n",
    "                if fail >= 3:\n",
    "                    break\n",
    "                continue\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "            if not page_list:\n",
    "                break\n",
    "            all_list.extend(page_list)\n",
    "            if len(page_list) < 100:\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "        return all_list\n",
    "    \n",
    "    \n",
    "def get_report_html(rcept_no: str, wait_sec=1.0) -> tuple:\n",
    "        url = f\"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}\"\n",
    "        opts = Options()\n",
    "        opts.add_argument(\"--headless\")\n",
    "        opts.add_argument(\"--disable-gpu\")\n",
    "        opts.add_argument(f\"user-agent={HEADERS['User-Agent']}\")\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "    \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(wait_sec)\n",
    "            driver.switch_to.frame(\"ifrm\")\n",
    "            time.sleep(wait_sec)\n",
    "            html = driver.page_source\n",
    "        except:\n",
    "            html = \"\"\n",
    "        finally:\n",
    "            driver.quit()\n",
    "        return rcept_no, html\n",
    "\n",
    "    # 1) 상장사 목록\n",
    "df_corps = load_corps()\n",
    "\n",
    "# 2) 모든 배당공시 메타 수집\n",
    "tasks = []\n",
    "for _, row in tqdm(df_corps.iterrows(), total=len(df_corps), desc=\"종목 처리\"):\n",
    "    for f in list_filings(row.corp_code):\n",
    "        if \"배당\" in f[\"report_nm\"]:\n",
    "            tasks.append({\n",
    "                \"corp_name\": row.corp_name,\n",
    "                \"stock_code\":row.stock_code,\n",
    "                \"rcept_dt\": f[\"rcept_dt\"],\n",
    "                \"report_nm\":f[\"report_nm\"],\n",
    "                \"rcept_no\":f[\"rcept_no\"]\n",
    "            })\n",
    "\n",
    "# 3) HTML 병렬 스크래핑\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=5) as exe:\n",
    "    futures = {exe.submit(get_report_html, t[\"rcept_no\"]):t for t in tasks}\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"HTML 수집\"):\n",
    "        meta = futures[fut]; rno, html = fut.result()\n",
    "        results.append({**meta, \"html\":html})\n",
    "\n",
    "# 4) DataFrame으로 변환 & 저장\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"data/dividend_with_text.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "with open(\"data/dividend_with_text.jsonl\",\"w\",encoding=\"utf-8\") as fw:\n",
    "    for rec in results:\n",
    "        fw.write(json.dumps(rec, ensure_ascii=False)+\"\\n\")\n",
    "\n",
    "df = pd.read_csv(\"data/dividend_with_text.csv\", encoding=\"utf-8-sig\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 원본 데이터: 15,996건\n",
      "✅ 상장 종목 필터링 후: 15,460건\n",
      "🏢 남은 기업 수: 1,682개\n",
      "💾 기존 파일 덮어쓰기 완료 → /Users/gun/Desktop/미래에셋 AI 공모전/data/dividend_ml_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "# 1. 파일 로드\n",
    "csv_path = \"/Users/gun/Desktop/미래에셋 AI 공모전/data/dividend_ml_ready.csv\"\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 2. 상장 종목 리스트 가져오기 (KRX 기준)\n",
    "krx_list = fdr.StockListing(\"KRX\")\n",
    "listed_codes = krx_list['Code'].astype(str).str.zfill(6).unique()\n",
    "\n",
    "# 3. 필터링: 현재 상장된 종목만 남기기\n",
    "df[\"stock_code\"] = df[\"stock_code\"].astype(str).str.zfill(6)\n",
    "filtered_df = df[df[\"stock_code\"].isin(listed_codes)].reset_index(drop=True)\n",
    "\n",
    "# 4. 덮어쓰기 저장 (기존 파일 대체)\n",
    "filtered_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 5. 요약 출력\n",
    "print(f\"📄 원본 데이터: {len(df):,}건\")\n",
    "print(f\"✅ 상장 종목 필터링 후: {len(filtered_df):,}건\")\n",
    "\n",
    "# ✅ 남은 고유 기업 수 확인\n",
    "unique_firms = filtered_df[\"stock_code\"].nunique()\n",
    "print(f\"🏢 남은 기업 수: {unique_firms:,}개\")\n",
    "\n",
    "print(f\"💾 기존 파일 덮어쓰기 완료 → {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제 대상 행 수: 0 / 전체 15460\n",
      "✅ 필터링 후 남은 행 수: 15460. 덮어쓰기 완료: /Users/gun/Desktop/미래에셋 AI 공모전/data/dividend_ml_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) ML용 CSV 로드\n",
    "path = \"/Users/gun/Desktop/미래에셋 AI 공모전/data/dividend_ml_ready.csv\"\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 2) per_share_common, yield_common, total_amount 중 하나라도 0인 경우\n",
    "mask_any_zero = (\n",
    "    (df.per_share_common == 0) |\n",
    "    (df.yield_common      == 0) |\n",
    "    (df.total_amount      == 0)\n",
    ")\n",
    "\n",
    "print(f\"삭제 대상 행 수: {mask_any_zero.sum()} / 전체 {len(df)}\")\n",
    "\n",
    "# 3) 필터링\n",
    "df_filtered = df[~mask_any_zero].reset_index(drop=True)\n",
    "\n",
    "# 4) 원본 파일 덮어쓰기 저장\n",
    "df_filtered.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ 필터링 후 남은 행 수: {len(df_filtered)}. 덮어쓰기 완료: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
